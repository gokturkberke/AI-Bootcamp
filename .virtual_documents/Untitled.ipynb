import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error , r2_score


df = sns.load_dataset("diamonds")


df.head()


df.tail()


df.describe().T


sns.scatterplot(x="carat",y="price",data=df,alpha=0.5)
plt.title("Elmas Karat iliskisi")
plt.xlabel("carat")
plt.ylabel("price")
plt.show()


X = df[["carat"]]
y = df[["price"]]


model = LinearRegression()
model.fit(X,y)


y_pred = model.predict(X)


mse = mean_squared_error(y,y_pred)


rmse=np.sqrt(mse)
r2 = r2_score(y,y_pred)


print(f"Mean Squared Error: {mse:.2f}")
print(f"Root Mean Squared Error: {rmse:.2f}")
print(f"R2 Squared Error: {r2:.2f}")


new_diamond = [[1.5]] #1.5 caratlik elmas
tahmini_fiyat = model.predict(new_diamond)[0]
print(f"1.5 karat elmas icin tahmini fiyat : {tahmini_fiyat[0]:.2f} $")








import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split,cross_validate
from sklearn.preprocessing import RobustScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score,roc_auc_score,confusion_matrix


def outlier_threshold(df,col,q1=0.05,q3=0.95):
    q1_val = df[col].quantile(q1)
    q3_val = df[col].quantile(q3)
    iqr = q3_val - q1_val
    low_limit = q1_val - 1.5 *iqr
    upper_limit = q3_val + 1.5 * iqr
    return low_limit,upper_limit


def replace_with_thresholds(df,col):
    low, up = outlier_threshold(df,col)
    df[col] = np.where(df[col] < low , low , np.where(df[col] > up,up,df[col]))
    # bu kod eger df[col] low dan kucukse low degilse ikinci np.where uygula df[col] > ise up bu da degilse aykiri deger degil


def plot_confusion_matrix(y_true,y_pred):
    acc = round(accuracy_score(y_true,y_pred),2)
    cm = confusion_matrix(y_true,y_pred)
    sns.heatmap(cm,annot=True,fmt="d")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title(f"Accuracy: {acc}")
    plt.show()


df = pd.read_csv("diabetes.csv")


target = "Outcome"


features = [col for col in df.columns if col != target]


for col in features:
    replace_with_thresholds(df,col)


scaler = RobustScaler()


df[features] = scaler.fit_transform(df[features]) #verilerinizdeki sayısal özellikleri belirli bir aralığa (genellikle 0 ile 1 arasına veya ortalaması 0, standart sapması 1 olacak şekilde) dönüştürerek makine öğrenmesi modelinin daha iyi performans göstermesini sağlar.


X = df[features]
y = df[target]


log_model = LogisticRegression().fit(X,y)
y_pred = log_model.predict(X)
y_prob = log_model.predict_proba(X)[:,1] #log_model isimli lojistik regresyon modelini kullanarak X veri setindeki her bir gözlem için "1" sınıfına (genellikle pozitif veya hedeflenen durum) ait olma olasılığını hesaplar.


print("Training Classification Report:\n", classification_report(y,y_pred))
plot_confusion_matrix(y,y_pred)
print("ROC AUC Score(Train):",roc_auc_score(y,y_prob))








import sys
!{sys.executable} -m pip install pydotplus


import sys
!{sys.executable} -m pip install skompiler


import warnings
import joblib

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Grafik ve model görselleştirme için
import pydotplus
from graphviz import Source

# Scikit-learn model ve metrikleri
from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, validation_curve
from sklearn.tree import DecisionTreeClassifier, export_graphviz, export_text, plot_tree
from sklearn.metrics import classification_report, roc_auc_score

# Diğer kütüphaneler
from skompiler import skompile

# Genellikle kullanılmayan uyarıları kapatmak için
warnings.filterwarnings('ignore')


warnings.simplefilter(action='ignore',category = Warning)
pd.set_option('display.max_columns',None)
pd.set_option('display.width',500)


df = pd.read_csv("diabetes.csv")


df.shape


df.head()


y = df["Outcome"]
X = df.drop("Outcome",axis=1)


model = DecisionTreeClassifier(random_state=1).fit(X,y)
y_pred = model.predict(X)
y_prob = model.predict_proba(X)[:,1]


print("Confusion Matrix: \n", classification_report(y,y_pred))
print("ROC AUC:", roc_auc_score(y,y_pred))


X_train, X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=17)


model = DecisionTreeClassifier(random_state=17).fit(X_train,y_train)


print("Eğitim Skoru (Train Score):\n", 
      classification_report(y_train, model.predict(X_train)))


print("Test Skoru (Test Score):\n", 
      classification_report(y_test, model.predict(X_test)))





cv_model = DecisionTreeClassifier(random_state=17)
cv_results = cross_validate(cv_model,X,y,cv=5, scoring=["accuracy","f1","roc_auc"])
print("CV Accuracy" , cv_results['test_accuracy'].mean())
print("CV F1", cv_results['test_f1'].mean())
print("CV ROC AUC", cv_results['test_roc_auc'].mean())


params = {"max_depth" : range(1,11),"min_samples_split": range(2,20)}
grid = GridSearchCV(cv_model,params,cv=5,n_jobs=-1,verbose=1).fit(X,y)

print("Best Params:",grid.best_params_)
print("Best CV Score",grid.best_score_)








def plot_feature_importance(model, features, num=10):
    feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': features.columns})
    plt.figure(figsize=(10, 8))
    sns.set(font_scale=1)
    sns.barplot(x="Value", y="Feature", data=feature_imp.sort_values(by="Value", ascending=False)[0:num])
    plt.title('Öznitelik Önem Düzeyleri (Feature Importances)')
    plt.ylabel('Öznitelikler (Features)')
    plt.xlabel('Önem Skoru')
    plt.tight_layout()
    plt.show()

plot_feature_importance(final_model, X)



